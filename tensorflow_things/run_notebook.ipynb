{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fauna-ing Over Animal Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You'll want to make a directory called 'project_name' or whatever\n",
    "2. Collect your data, you'll want pictures for each class, with bounding boxes and class labels etc. in XML files. People like [OpenCV](https://opencv.org/) but use whatever you like/want/can find the most stack overflow comments on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the things you'll need to download to start using this repo. I'll try and make this step-by-step to get you up and running.\n",
    "\n",
    "Clone the [tensorflow_things directory](https://github.com/MasonCaiby/Boulder_AI_CPW_study/tree/master/tensorflow_things) into your `project_name` directory\n",
    "\n",
    "Clone the [tensorflow models/research repo](https://github.com/tensorflow/models) into the cloned `project_name/tensorflowthings` (this) directory. \n",
    "  follow the install instructions [from tensorflow](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)\n",
    "\n",
    "Navigate to models/research in your terminal and copy/paste this code into term (you can also add it to your Bash Profile): \n",
    "\n",
    "    ```export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the TFRecords\n",
    "\n",
    "These records contain all of the data you will need to train your model. This means you will not need to upload your images to [AWS].\n",
    "\n",
    "### First we need to get the images arranged correctly\n",
    "\n",
    "The xml_to_csv will recursively check to make sure it gets all sub directories of `.../tensorflow_things/image_annotations/...`, so the structure of `.../images/` and `.../annotations/` doesn't matter too much\n",
    "\n",
    "Put your training images in a folder called `.../tensorflow_things/image_annotations/images`\n",
    "\n",
    "Put your training annotations in a folder called `.../tensorflow_things/image_annotations/annotations`. The name of the object for each bounding box can be in the xml file OR the folder name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make CSV's of the bounding boxes\n",
    "\n",
    "Run the ```xml_to_csv.py``` script. This will create a ```test.csv``` and ```train.csv``` file - the files wil be mixed but you must make sure you have the correct number of images for each class (e.g. balanced classes). How you obtain this is up to you: you can up sample, down sample, or just get the right number of images for each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "run xml_to_csv.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the TFRecords\n",
    "\n",
    "We now need to make the tensorflow record files. These store your images and bounding box information. THIS MEANS YOU WILL NOT NEED TO UPLOAD YOUR TRAINING IMAGES TO AWS OR WHEREVER YOU CHOOSE TO TRAIN YOUR MODEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718592 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 395876289 bytes but only got 0. Skipping tag 34464\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12976128 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2686976 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3211264 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8388608 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9437184 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25165824 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14155776 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 35127296 bytes but only got 1080. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /Users/maxcaudle/projects/capstone_backup/tensorflow_things/train2.record\n"
     ]
    }
   ],
   "source": [
    "run generate_tfrecord.py  --csv_input=image_annotations/train.csv --output_path=train.record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will allow you to use generate_tfrecord.py again within this notebook. \n",
    "# Jupyter Notebook's store tf flags in memory and you can't change them (from what I can tell)\n",
    "# once you've used the script once. We have made any variables so the reset is safe.\n",
    "\n",
    "%reset -sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 4718592 bytes but only got 0. Skipping tag 0\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 395876289 bytes but only got 0. Skipping tag 34464\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 12976128 bytes but only got 0. Skipping tag 2\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 2686976 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 3211264 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 131072 bytes but only got 0. Skipping tag 3\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8388608 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 9437184 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 25165824 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 14155776 bytes but only got 0. Skipping tag 5\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 35127296 bytes but only got 1080. Skipping tag 4\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:709: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecords: /Users/maxcaudle/projects/capstone_backup/tensorflow_things/test2.record\n"
     ]
    }
   ],
   "source": [
    "run generate_tfrecord.py --csv_input=image_annotations/test.csv --output_path=test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get some bad tag warnings, and I have ignored them. People online seem to do the same thing. My model still trained. The error is:\n",
    "\n",
    "```\n",
    "\" Skipping tag %s\" % (size, len(data), tag))\n",
    "/Users/maxcaudle/anaconda3/lib/python3.6/site-packages/PIL/TiffImagePlugin.py:692: UserWarning: Possibly corrupt EXIF data.  Expecting to read 35127296 bytes but only got 1080. Skipping tag 4\n",
    "```\n",
    "\n",
    "You should now have a `test.record` and `train.record` file in your `.../tensorflow_things/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "### Get a pretrained model and config file\n",
    "\n",
    "Sweet now you have your tfrecord files. Now we have to copy some things into the tensorflow_things directory. You'll adopt this for whichever model you wish to use (I used ```faster_rcnn_inception_resnet_v2_atrous_coco```).\n",
    "\n",
    "    a. the config file for the model you want to use from [here](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs). \n",
    "  \n",
    "    b. the tar'ed directory of the last checkpoint from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit the config file to what you need.\n",
    "\n",
    "Change the config file to have the correct number of classes (for the faster rcnn it is num_classes) here:\n",
    "```\n",
    "model {\n",
    "  faster_rcnn {\n",
    "    num_classes: 3\n",
    "    image_resizer {\n",
    "      fixed_shape_resizer {\n",
    "        height: 300\n",
    "        width: 300\n",
    "```\n",
    "\n",
    "Change the filepaths to point to the correct location, they are in all caps. For the [faster_rcnn](https://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config) I used they are:\n",
    "\n",
    "#### a. line 108: \n",
    "    \n",
    "```\n",
    "fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/model.ckpt\"\n",
    "```  \n",
    "to\n",
    "\n",
    "```\n",
    "fine_tune_checkpoint: \"faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28/model.ckpt\"\n",
    "```\n",
    "        \n",
    "#### b. line 123: \n",
    "```\n",
    "input_path: \"PATH_TO_BE_CONFIGURED/mscoco_train.record\"\n",
    "``` \n",
    "to \n",
    "```\n",
    "input_path: \"train.record\"\n",
    "```\n",
    "       \n",
    "#### c. line 125: \n",
    "```\n",
    "label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n",
    "``` \n",
    "to\n",
    "```\n",
    "label_map_path: \"object-detection.pbtxt\"\n",
    "```\n",
    "       \n",
    "#### d. line 137: \n",
    "```\n",
    "input_path: \"PATH_TO_BE_CONFIGURED/mscoco_val.record\"\n",
    "``` \n",
    "to\n",
    "```\n",
    "input_path: \"test.record\"\n",
    "```\n",
    "       \n",
    "#### e. line 139: \n",
    "```\n",
    "label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n",
    "``` \n",
    "to\n",
    "```\n",
    "label_map_path: \"object-detection.pbtxt\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "You can run the model from your CL with:\n",
    "`python models/research/object_detection/train.py --logtostderr --train_dir=training_faster_smaller_lr_1_3/ --pipeline_config_path=faster_rcnn_inception_resnet_v2_atrous_coco.config`\n",
    "\n",
    "Or just run the cell below. (Note, this might choke your computer, depending on you know, your computer).\n",
    "\n",
    "If you get a `ModuleNotFoundError: No module named 'object_detection'` error, you need to re-export the object detection directory. In your CL you need to go to `.../tensorflow_things/models/research/` directory and c/p : ```\n",
    "export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim\n",
    "```\n",
    "\n",
    "Note: If you are running this in a JN and are getting the module error, you'll have to export it then run JN from tensorflow_things in the same CL tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'object_detection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/projects/capstone_backup/tensorflow_things/models/research/object_detection/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'"
     ]
    }
   ],
   "source": [
    "run models/research/object_detection/train.py --logtostderr --train_dir=training_directory/ --pipeline_config_path=faster_rcnn_inception_resnet_v2_atrous_coco.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained model\n",
    "\n",
    "Now you need to let the model train. You can check the tensorboard here: `tensorboard --logdir='training_directory'`\n",
    "When to stop letting the model train is up to you. You are, after all, the data scientist. I would urge you to wait until the error is <1, or maybe <<1. It's up to you though. Once you're satisfied with your model's progress, move to the next step.\n",
    "\n",
    "Alternatively, you can move to the next step while your model is still training, check it on a few images, then either decide to stop training it or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a frozen model\n",
    "This is pretty straight forward, thanks to TF's code base just c/p this command, after making sure the flags are set correctly (check: pipeline_config_path, trained_checkpoint_prefix, output_directory)\n",
    "\n",
    "```\n",
    "python3 object_detection/export_inference_graph.py \\\n",
    "--input_type image_tensor \\\n",
    "--pipeline_config_path ${PIPELINE_CONFIG_PATH} \\\n",
    "--trained_checkpoint_prefix ${TRAIN_PATH} \\\n",
    "--output_directory output_inference_graph.pb\n",
    "```\n",
    "An example of my code is:\n",
    "\n",
    "```\n",
    "python3 \"models/research/object_detection/export_inference_graph.py\" \\\n",
    "--input_type image_tensor \\\n",
    "--pipeline_config_path \"faster_rcnn_inception_resnet_v2_atrous_coco1.config\" \\\n",
    "--trained_checkpoint_prefix \"training_faster1/model.ckpt-13972\" \\\n",
    "--output_directory \"full_inference_graph_maybe/\"\n",
    "```\n",
    "\n",
    "I am choosing not to add this into a runable cell, because your variables will, well, vary. I did; however, include a blank Python cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats, you now have a model.\n",
    "\n",
    "You can now use either the ```object_detection_tutorial.ipynb``` or ```test_pipe_aws.py``` file to test your images.\n",
    "\n",
    "I'd suggest looking at the test_pipe_aws.py if you wish to use it. You can also contact me at: ```maxwell.caudle@gmail.com``` if you have any questions on anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
